= Configure Metrics and Log Forwarding to Azure Files

OpenShift stores logs and metrics inside the cluster by default, however it also provides tooling to forward both to various locations.
Here we will configure ARO to forward logs and metrics to Azure Files and use Grafana to view them.

. Create a Storage Account:
+
[source,sh,role=execute]
----
AZR_STORAGE_ACCOUNT_NAME="storage${GUID}"

ARO_LOCATION=$(az aro show --resource-group openenv-${GUID} --name aro-cluster-${GUID} --query location -o tsv)

az storage account create --name "${AZR_STORAGE_ACCOUNT_NAME}" --resource-group "openenv-${GUID}" --location "${AZ_LOCATION}" --sku Standard_LRS
----
+
.Sample Output
[source,text,options=nowrap]
----
The public access to all blobs or containers in the storage account will be disallowed by default in the future, which means default value for --allow-blob-public-access is still null but will be equivalent to false.
{
  "accessTier": "Hot",
  "allowBlobPublicAccess": true,

[... Lots of output Omitted ...]
----

. Fetch your storage account key
+
[source,sh,role=execute]
----
AZR_STORAGE_KEY=$(az storage account keys list --resource-group "openenv-${GUID}" -n "${AZR_STORAGE_ACCOUNT_NAME}" --query "[0].value" -o tsv)

echo ${AZR_STORAGE_KEY}
----
+
.Sample Output
[source,text,options=nowrap]
----
gr6ujd144KyO14BVQ5cEupJw/MWQx/XvXxQE/eG62oOvoVfnLVO68EcFGDygSXQD4pUGx+oA+wNJ+AStwccBSw==
----

. Create a storage bucket for logs:
+
[source,sh,role=execute]
----
az storage container create --name "aro-logs" \
  --account-name "${AZR_STORAGE_ACCOUNT_NAME}" \
  --account-key "${AZR_STORAGE_KEY}"
----
+
.Sample Output
[source,text,options=nowrap]
----
{
  "created": true
}
----

. Create a storage bucket for metrics:
+
[source,sh,role=execute]
----
az storage container create --name "aro-metrics" \
  --account-name "${AZR_STORAGE_ACCOUNT_NAME}" \
  --account-key "${AZR_STORAGE_KEY}"
----
+
.Sample Output
[source,text,options=nowrap]
----
{
  "created": true
}
----

. Deploy ElasticSearch CRDs (not used, but needed for a https://access.redhat.com/solutions/6990588[bug workaround]):
+
[source,sh,role=execute]
----
oc create -f https://raw.githubusercontent.com/openshift/elasticsearch-operator/release-5.5/bundle/manifests/logging.openshift.io_elasticsearches.yaml
----
+
.Sample Output
[source,text,options=nowrap]
----
customresourcedefinition.apiextensions.k8s.io/elasticsearches.logging.openshift.io created
----

. Download and set up the `helm` template manager:
+
[source,sh,role=execute]
----
cd $HOME

wget https://mirror.openshift.com/pub/openshift-v4/clients/helm/latest/helm-linux-amd64.tar.gz -O ~/helm.tar.gz

tar -xvf ~/helm.tar.gz

mkdir ~/bin

mv ~/helm-linux-amd64 ~/bin/helm

rm ~/helm.tar.gz
----

. Check that `helm` is installed properly:
+
[source,sh,role=execute]
----
helm version
----
+
.Sample Output
[source,text,options=nowrap]
----
version.BuildInfo{Version:"v3.11.1+6.el8", GitCommit:"66bfc44f827aea6eb8e001150914170ac0d49e2d", GitTreeState:"clean", GoVersion:"go1.18.9"}
----

. Set up the MOBB Helm Chart Repository:
+
[source,sh,role=execute]
----
helm repo add mobb https://rh-mobb.github.io/helm-charts/

helm repo update
----
+
.Sample Output
[source,text,options=nowrap]
----
"mobb" has been added to your repositories
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the "mobb" chart repository
Update Complete. ⎈Happy Helming!⎈
----

. Create a project to deploy the Helm charts into:
+
[source,sh,role=execute]
----
oc new-project custom-logging
----
+
.Sample Output
[source,text,options=nowrap]
----
Now using project "custom-logging" on server "https://api.rbrlitrg.westeurope.aroapp.io:6443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app rails-postgresql-example

to build a new example application in Ruby. Or use kubectl to deploy a simple Kubernetes application:

    kubectl create deployment hello-node --image=k8s.gcr.io/e2e-test-images/agnhost:2.33 -- /agnhost serve-hostname
----

. Create list of Operators to install:
+
[source,sh,role=execute]
----
cat <<EOF > clf-operators.yaml
subscriptions:
- name: grafana-operator
  channel: v4
  installPlanApproval: Automatic
  source: community-operators
  sourceNamespace: openshift-marketplace
- name: cluster-logging
  channel: stable
  installPlanApproval: Automatic
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  namespace: openshift-logging
- name: loki-operator
  channel: stable
  installPlanApproval: Automatic
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  namespace: openshift-operators-redhat
- name: resource-locker-operator
  channel: alpha
  installPlanApproval: Automatic
  source: community-operators
  sourceNamespace: openshift-marketplace
  namespace: resource-locker-operator
operatorGroups:
- name: custom-logging
  targetNamespace: ~
- name: openshift-logging
  namespace: openshift-logging
  targetNamespace: openshift-logging
- name: openshift-operators-redhat
  namespace: openshift-operators-redhat
  targetNamespace: all
- name: resource-locker
  namespace: resource-locker-operator
  targetNamespace: all
EOF
----

. Deploy the Grafana, Cluster Logging, and Loki Operator from the file just created above using Helm:
+
[source,sh,role=execute]
----
oc create ns openshift-logging

oc create ns openshift-operators-redhat

oc create ns resource-locker-operator

helm upgrade -n custom-logging clf-operators \
  mobb/operatorhub --install \
  --values ./clf-operators.yaml
----
+
.Sample Output
[source,text,options=nowrap]
----
namespace/openshift-logging created
namespace/openshift-operators-redhat created
namespace/resource-locker-operator created
Release "clf-operators" does not exist. Installing it now.
NAME: clf-operators
LAST DEPLOYED: Tue Jun  6 09:40:28 2023
NAMESPACE: custom-logging
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
.
----

. Wait for the Operators to be installed.
+
[INFO]
====
These commands will loop through each type of resource until the CRDs for the Operators have been deployed.

Eventually you'll see the message `No resources found in custom-logging namespace` and be returned to a prompt.
====
+
[source,sh,role=execute]
----
while ! oc get grafana; do sleep 5; echo -n .; done
while ! oc get clusterlogging; do sleep 5; echo -n .; done
while ! oc get lokistack; do sleep 5; echo -n .; done
while ! oc get resourcelocker; do sleep 5; echo -n .; done
----
+
.Sample Output
[source,text,options=nowrap]
----
No resources found in custom-logging namespace.
No resources found in custom-logging namespace.
No resources found in custom-logging namespace.
No resources found in custom-logging namespace.
----

. Deploy Helm Chart to deploy Grafana and forward metrics to Azure:
+
[source,sh,role=execute]
----
helm upgrade -n "custom-logging" aro-thanos-af \
  --install mobb/aro-thanos-af --version 0.4.1 \
  --set "aro.storageAccount=${AZR_STORAGE_ACCOUNT_NAME}" \
  --set "aro.storageAccountKey=${AZR_STORAGE_KEY}" \
  --set "aro.storageContainer=aro-metrics" \
  --set "enableUserWorkloadMetrics=true"
----
+
.Sample Output
[source,text,options=nowrap]
----
Release "aro-thanos-af" does not exist. Installing it now.
NAME: aro-thanos-af
LAST DEPLOYED: Tue Jun  6 09:42:05 2023
NAMESPACE: custom-logging
STATUS: deployed
REVISION: 1
TEST SUITE: None
----

. Validate Grafana is accessible, by fetching it's Route and browsing to it with your web browser.
+
[source,sh,role=execute]
----
oc -n custom-logging get route grafana-route \
  -o jsonpath='{"https://"}{.spec.host}{"\n"}'
----
+
.Sample Output
[source,text,options=nowrap]
----
https://grafana-route-custom-logging.apps.rbrlitrg.westeurope.aroapp.io
----

. Then click on the `AAD` authentication provider - you should already be logged into the cluster because you logged into the web console earlier. Accept all permissions by clicking on *Allow selected permissions*. You should see the Grafana dashboard.
+
[WARNING]
====
If your browser displays an error that says _'Application is not available'_ wait a minute and try again.

If it persists you've hit a race condition with certificate creation.

Run the following command to try to resolve it:

[source,sh,role=execute]
----
oc patch -n custom-logging service grafana-alert -p '{ "metadata": { "annotations": null }}'

oc -n custom-logging delete secret aro-thanos-af-grafana-cr-tls

oc patch -n custom-logging service grafana-service \
    -p '{"metadata":{"annotations":{"retry": "true" }}}'

sleep 5

oc -n custom-logging rollout restart deployment grafana-deployment
----
====

. Deploy Helm Chart to enable Cluster Log forwarding to Azure:
+
[source,sh,role=execute]
----
helm upgrade -n custom-logging aro-clf-blob \
  --install mobb/aro-clf-blob --version 0.1.1 \
  --set "azure.storageAccount=${AZR_STORAGE_ACCOUNT_NAME}" \
  --set "azure.storageAccountKey=${AZR_STORAGE_KEY}" \
  --set "azure.storageContainer=aro-logs"
----
+
.Sample Output
[source,text,options=nowrap]
----
Release "aro-clf-blob" does not exist. Installing it now.
NAME: aro-clf-blob
LAST DEPLOYED: Tue Jun  6 09:47:38 2023
NAMESPACE: custom-logging
STATUS: deployed
REVISION: 1
TEST SUITE: None
----

. Wait for the Log Collector agent to be started:
+
[source,sh,role=execute]
----
oc -n openshift-logging rollout status daemonset collector
----
+
.Sample Output
[source,text,options=nowrap]
----
daemon set "collector" successfully rolled out
----

. Restart Log Collector:
+
[source,sh,role=execute]
----
oc -n openshift-logging rollout restart daemonset collector
----
+
.Sample Output
[source,text,options=nowrap]
----
Warning: spec.template.metadata.annotations[scheduler.alpha.kubernetes.io/critical-pod]: non-functional in v1.16+; use the "priorityClassName" field instead
daemonset.apps/collector restarted
----
+
[INFO]
====
Sometimes the log collector agent starts before the operator has finished configuring Loki, restarting it here will resolve the issue.

The message about `priorityClassName` can be safely ignored.
====

== View the Metrics and Logs

Now that the Metrics and Log forwarding is set up we can view them in Grafana.

. Fetch the Route for Grafana again:
+
[source,sh,role=execute]
----
oc -n custom-logging get route grafana-route \
   -o jsonpath='{"https://"}{.spec.host}{"\n"}'
----
+
.Sample Output
[source,text,options=nowrap]
----
https://grafana-route-custom-logging.apps.rbrlitrg.westeurope.aroapp.io
----

. Browse to the provided route address in the same browser window as your OCP console and login using your OpenShift credentials (either AAD or kubeadmin). If you tested this before you are already logged in.

. View an existing dashboard such as *custom-logging \-> Node Exporter \-> USE Method \-> Cluster* (click on the *search* icon on the left to see the *custom-logging* dashboard).
+
[INFO]
====
These dashboards are copies of the dashboards that are available directly on the OpenShift web console under *Observability*".
====
+
image::../../media/grafana-metrics.png[]

. Click the Explore (compass) Icon in the left hand menu, select "`Loki (Application)`" in the dropdown and search for `{kubernetes_namespace_name="custom-logging"}`
+
image::../../media/grafana-logs.png[]
